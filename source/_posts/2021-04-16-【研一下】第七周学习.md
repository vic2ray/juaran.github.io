---

title: 【研一下】第七周学习汇报
date: 2021-4-17
category: 机器学习
tag: 周报
---



## VGG16-CIFAR10

### 1. 网络模型

![一文读懂VGG网络](https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/v2-dfe4eaaa4450e2b58b38c5fe82f918c0_1440w.jpg)

不同深度的VGG卷积神经网络结构：

![img](https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/v2-ea924e733676e0da534f677a97c98653_r.jpg)

在对CIFAR10数据分类的实验中，我们选择VGG-16，即构造16个隐含层的卷积神经网络，输入层为32*32\*3的彩色图片，输出层为0-9的分类标签。

使用Pytorch构造网络VGG-16如下：

``` python
from torch import nn
 
# 构建网络模型
class VGG16(nn.Module):
    def __init__(self):
        super(VGG16, self).__init__()
        self.net = nn.Sequential(
            # input: [batch, channel, width, height] = [batch, 3, 224, 224]
            # VGG 1st layer : 1st conv3-64 : [batch, 3, 224, 224] -> [batch, 64, 224, 224]
            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),
            nn.ReLU(),
            # VGG 2nd layer : 2nd conv3-64 : [batch, 64, 224, 224] -> [batch, 64, 224, 224]
            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),
            nn.ReLU(),
            # 1st maxpool : [batch, 64, 224, 224] -> [batch, 64, 112, 112]
            nn.MaxPool2d(kernel_size=2, stride=2),
            # VGG 3rd layer : 1st conv3-128 : [batch, 64, 224, 224] -> [batch, 128, 224, 224]
            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),
            nn.ReLU(),
            # VGG 4th layer : 2rd conv3-128 : [batch, 128, 224, 224] -> [batch, 128, 224, 224]
            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),
            nn.ReLU(),
            # 2nd maxpool : [batch, 128, 224, 224] -> [batch, 128, 56, 56]
            nn.MaxPool2d(kernel_size=2, stride=2),
            # VGG 5th layer : 1st conv3-256 : [batch, 128, 56, 56] -> [batch, 256, 56, 56]
            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),
            nn.ReLU(),
            # VGG 6th layer : 2nd conv3-256 : [batch, 256, 56, 56] -> [batch, 256, 56, 56]
            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),
            nn.ReLU(),
            # VGG 7th layer : 3rd conv3-256 : [batch, 256, 56, 56] -> [batch, 256, 56, 56]
            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),
            nn.ReLU(),
            # 3rd maxpool : [batch, 256, 56, 56] -> [batch, 256, 28, 28]
            nn.MaxPool2d(kernel_size=2, stride=2),
            # VGG 8th layer : 1st conv3-512 : [batch, 256, 56, 56] -> [batch, 512, 56, 56]
            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),
            nn.ReLU(),
            # VGG 9th layer : 2nd conv3-512 : [batch, 512, 56, 56] -> [batch, 512, 56, 56]
            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),
            nn.ReLU(),
            # VGG 10th layer : 3rd conv3-512 : [batch, 512, 56, 56] -> [batch, 512, 56, 56]
            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),
            nn.ReLU(),
            # 4th maxpool : [batch, 512, 28, 28] -> [batch, 512, 14, 14]
            nn.MaxPool2d(kernel_size=2, stride=2),
            # VGG 11th layer : 1st conv3-512 : [batch, 512, 14, 14] -> [batch, 512, 14, 14]
            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),
            nn.ReLU(),
            # VGG 12th layer : 2nd conv3-512 : [batch, 512, 14, 14] -> [batch, 512, 14, 14]
            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),
            nn.ReLU(),
            # VGG 13th layer : 3rd conv3-512 : [batch, 512, 14, 14] -> [batch, 512, 14, 14]
            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),
            nn.ReLU(),
            # 5th maxpool : [batch, 512, 28, 28] -> [batch, 512, 7, 7]  ->
            nn.MaxPool2d(kernel_size=2, stride=2),
            # Flatten maxpool layer -> [batch, 512, 7, 7]  ->  [batch, 512 * 7 * 7]
            nn.Flatten(),     
            # VGG 14th layer : full connect 4096
            nn.Linear(in_features=512, out_features=100),
            nn.ReLU(),
            # VGG 15th layer : full connect 4096
            nn.Linear(in_features=100, out_features=100),
            nn.ReLU(),
            # VGG 16th layer : full connect 4096
            nn.Linear(in_features=100, out_features=10),
            nn.ReLU(),
        )
 
    def forward(self, x):
        return self.net(x)
```

注意：在最后三个全连接层需要根据输入图像大小进行调整。按照VGG原实验，当输入图像大小为224*224\*3时，第一个全连接层输入为512\*7\*7，输出为4096（FC-4096、FC-4096、FC-10）；在CIFAR10数据集上，输入图像32\*32\*3，得到第一个全连接层输入为512\*1\*1，相应的将全连接层输出调整为100（FC-100、FC-100、FC-10）。

参考论文：

[1] [VERY DEEP CONVOLUTIONA NETWORK FO LARGE-SCAL IMAG RECOGNITION](https://arxiv.org/pdf/1409.1556.pdf)

[2] [VGG系列(Pytorch实现)](https://blog.csdn.net/zhanghao3389/article/details/85038252)

[3] [一文读懂VGG网络](https://zhuanlan.zhihu.com/p/41423739)

### 2. 数据集

<img src="https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20210417153955757.png" alt="image-20210417153955757" style="zoom:80%;" />

[CIFAR10](http://www.cs.toronto.edu/~kriz/cifar.html)数据集由6000张32*32的彩色图像、10个分类组成，每一类别各有6000张，50000张用于训练，10000张用于测试。

Pytorch对CIFAR10数据集做了封装，数据保存在二进制文件中，可以通过对应函数调用数据内容和属性。

``` python
# 下载训练和测试数据集
train_dataset = datasets.CIFAR10(
    root='cifar10',  # 数据集根目录
    transform=transforms.ToTensor(),  # 转换为Tensor
    download=True,  # 没有则下载
    train=True)  # 训练数据集
test_dataset = datasets.CIFAR10(
    root='cifar10',  # 数据集根目录
    transform=transforms.ToTensor(),  # 转换为Tensor
    download=True,  # 没有则下载
    train=False)  # 测试数据集
```

### 3. 训练

#### 3.1 模型参数量统计

``` python
from torchsummary import summary
 
device = torch.device('cuda:0')        # 获取显卡设备
model = VGG16()
model.to(device)        # 使用显卡加载模型
summary(moduel, input_size=(3, 32, 32))     # 统计模型参数量
```

> \----------------------------------------------------------------
>     Layer (type)               Output Shape         Param \#
> \====================================
>             Conv2d-1           [-1, 64, 32, 32]           1,792
>               ReLU-2           [-1, 64, 32, 32]               0
>             Conv2d-3           [-1, 64, 32, 32]          36,928
>               ReLU-4           [-1, 64, 32, 32]               0
>          MaxPool2d-5           [-1, 64, 16, 16]               0
>             Conv2d-6          [-1, 128, 16, 16]          73,856
>               ReLU-7          [-1, 128, 16, 16]               0
>             Conv2d-8          [-1, 128, 16, 16]         147,584
>               ReLU-9          [-1, 128, 16, 16]               0
>         MaxPool2d-10            [-1, 128, 8, 8]               0
>            Conv2d-11            [-1, 256, 8, 8]         295,168
>              ReLU-12            [-1, 256, 8, 8]               0
>            Conv2d-13            [-1, 256, 8, 8]         590,080
>              ReLU-14            [-1, 256, 8, 8]               0
>            Conv2d-15            [-1, 256, 8, 8]         590,080
>              ReLU-16            [-1, 256, 8, 8]               0
>         MaxPool2d-17            [-1, 256, 4, 4]               0
>            Conv2d-18            [-1, 512, 4, 4]       1,180,160
>              ReLU-19            [-1, 512, 4, 4]               0
>            Conv2d-20            [-1, 512, 4, 4]       2,359,808
>              ReLU-21            [-1, 512, 4, 4]               0
>            Conv2d-22            [-1, 512, 4, 4]       2,359,808
>              ReLU-23            [-1, 512, 4, 4]               0
>         MaxPool2d-24            [-1, 512, 2, 2]               0
>            Conv2d-25            [-1, 512, 2, 2]       2,359,808
>              ReLU-26            [-1, 512, 2, 2]               0
>            Conv2d-27            [-1, 512, 2, 2]       2,359,808
>              ReLU-28            [-1, 512, 2, 2]               0
>            Conv2d-29            [-1, 512, 2, 2]       2,359,808
>              ReLU-30            [-1, 512, 2, 2]               0
>         MaxPool2d-31            [-1, 512, 1, 1]               0
>           Flatten-32                  [-1, 512]               0
>            Linear-33                  [-1, 100]          51,300
>              ReLU-34                  [-1, 100]               0
>            Linear-35                  [-1, 100]          10,100
>              ReLU-36                  [-1, 100]               0
>            Linear-37                   [-1, 10]           1,010
>              ReLU-38                   [-1, 10]               0
>
> ====================================
> Total params: 14,777,098
> Trainable params: 14,777,098
> Non-trainable params: 0
> \----------------------------------------------------------------
> Input size (MB): 0.01
> Forward/backward pass size (MB): 4.46
> Params size (MB): 56.37
> Estimated Total Size (MB): 60.85
> \----------------------------------------------------------------

#### 3.2 开始训练

``` python
import torch
from torch import optim
from torch.utils.data import DataLoader
 
def train(model):
    # 训练设置
    epochs = 50  # 训练轮数
    display = 100  # 显示步长
    train_batch_size = 32  # 训练批次大小
    # 数据加载器（迭代器，每次迭代返回一个batch大小的数据data+标签target）
    train_dataloader = DataLoader(dataset=train_dataset, batch_size=train_batch_size, shuffle=True)
    # 优化器、损失函数
    optimizer = optim.Adam(params=moduel.parameters(), lr=1e-3)
    criteon = torch.nn.CrossEntropyLoss()  # 交叉熵损失
    # 开启训练
    moduel.train()
    for epoch in range(epochs):
        for i, train_data in enumerate(train_dataloader):
            # 正向传播
            data, target = train_data  # 获取数据和标签
            data = data.to(device)    # 数据载入显卡
            target = target.to(device)    # 数据载入显卡
            pred = moduel(data)  # 模型输出预测值
            loss = criteon(pred, target)  # 损失
            # 反向传播
            optimizer.zero_grad() 
            loss.backward()
            optimizer.step()
            # 显示Loss
            if i % display == 0:
                print('Epoch', epoch + 1, (i + 1) * train_batch_size, '/ 50000', 'Loss', loss.item())
        # 每10轮保存一次模型
        if epoch % 10 == 0:  
            model_epoch = 'models/cifar10_epoch_' + str(epoch+10) + '.pth'
            torch.save(obj=moduel.state_dict(), f=model_epoch)
```

#### 3.3 模型调参

在使用Pytorch搭建VGG16网络模型训练CIFAR10分类数据集的过程中，遇到**Loss一直不下降**的问题：

> Epoch 1 128 / 50000 Loss 2.308591842651367
> Epoch 2 128 / 50000 Loss 2.3025848865509033
> Epoch 3 128 / 50000 Loss 2.3025848865509033
> Epoch 4 128 / 50000 Loss 2.3025848865509033
> Epoch 5 128 / 50000 Loss 2.3025848865509033
> ......

参考博客：

[神经网络训练时损失(loss)不下降常见解决办法以及训练时损失出现nan可能原因以及解决](https://blog.csdn.net/dl962454/article/details/109624917)

1. 模型结构和特征工程存在问题——修正网络结构，检查参数是否错误
2. 权重初始化方案有问题——[PyTorch学习之十一种权重初始化方法](https://blog.csdn.net/shanglianlm/article/details/85165523)
3. 正则化过度，模型欠拟合
4. 选择合适的激活函数、损失函数
5. 选择合适的优化器和学习率——Adam、SGD
6. 梯度消失、梯度爆炸——使用Dropout、BatchNorm等方法减少学习参数
7. batch_size不合理
8. 数据集本身有问题——作无量纲化、打乱等理
9. 训练时间不够长

[vgg16从头训练loss不变的解决方法](https://blog.csdn.net/sugarfreewang/article/details/93976701)

最终，发现是优化器的选择不合适，当使用**Adagrad优化器**后，Loss瞬间下降了许多：

> Epoch 1 12832 / 50000 Loss 2.197270393371582
> Epoch 1 16032 / 50000 Loss 2.1675164699554443
> Epoch 1 19232 / 50000 Loss 2.0508370399475098
> Epoch 1 22432 / 50000 Loss 1.837303638458252
> Epoch 1 25632 / 50000 Loss 1.862862467765808

在此基础上，进行合适的**权重初始化**方案加快收敛速度。

``` python
# ... 优化器和损失
# Xavier初始化权重
for m in model.modules():
    if isinstance(m, (nn.Conv2d, nn.Linear)):
        nn.init.xavier_uniform_(m.weight)
```

### 4. 验证

上一步得到最终训练模型并保存为`cifar10_epoch_50.pth`，损失已经降至低于0.01，加载该模型评估其对验证集数据的预测准确度。

``` python
def validate(model):
    # 验证数据批加载器
    test_batch_size = 64  # 测试批次大小
    test_dataloader = DataLoader(dataset=train_dataset, batch_size=test_batch_size, shuffle=True)
    # 加载训练模型
    model.load_state_dict(torch.load('models/cifar10_epoch_50.pth'))
    # 进行验证
    model.eval()
    acc = 0
    total = 0
    with torch.no_grad():
        for data, target in test_dataloader:
            data = data.to(device)
            target = target.to(device)
            pred = model(data).argmax(dim=1)
            acc += torch.eq(pred, target).float().sum().item()
            total += data.size(0)
 
        acc = acc / total
        print('Validate accuracy:{}'.format(acc))
```

> Validate accuracy:0.99086

结果显示，训练所得模型对测试集数据预测准确度高达99%，能够使用该模型对新的数据进行预测。

### 5. 可视化

建立新的VGG16模型，加载已训练好的模型参数state_dict，获取每一层的参数Weight和Bias，依次对输入图像进行卷积、激活、池化操作，将每一层的feature map可视化输出。由于每一层卷积核数量不同，随机选取10个卷积核对应的feature map。一共16层，最后三层为全连接层，最后输出是是类别预测的概率值。可视化情况如下：

![image-20210419111923873](https://cdn.jsdelivr.net/gh/juaran/juaran.github.io@image/typora/image-20210419111923873.png)

代码较乱，待整理。

参考：

[pytorch中的卷积操作详解](https://blog.csdn.net/qq_37541097/article/details/102926037)

[python matplotlib这么同时显示多张图片在同一个图中](https://blog.csdn.net/qwe2508/article/details/88078746)

[【总结】Keras+VGG16特征图可视化，帮助你深入理解VGG16](https://blog.csdn.net/weixin_43836548/article/details/105356895)

[pytorch之卷积模块、池化、激活函数（可视化）](https://blog.csdn.net/weixin_40123108/article/details/83510592)

[Pytorch查看模型指定层的参数](https://blog.csdn.net/hhy_csdn/article/details/114031666)

[使用jupyter显示模型各层数据和参数](https://blog.csdn.net/hhh0209/article/details/73863888)

[CNN的一些可视化方法](https://zhuanlan.zhihu.com/p/53683453)