---

title: 【研一下】第六周学习汇报
date: 2021-4-9
category: 机器学习
tag: 周报

---



## PyTorch训练CIFAR10分类任务

### 1. 数据集加载

``` python
from torchvision import datasets, transforms
 
# 下载数据集
train_dataset = \
    datasets.CIFAR10(root='cifar10',  # 数据集根目录
                     transform=transforms.Compose([
                         transforms.ToTensor(),  # 转换为Tensor
                         transforms.Resize([32, 32])]),  # 转换大小
                     download=True,  # 没有则下载
                     train=True)  # 训练数据集
test_dataset = \
    datasets.CIFAR10(root='cifar10',  # 数据集根目录
                     transform=transforms.Compose([
                         transforms.ToTensor(),  # 转换为Tensor
                         transforms.Resize([32, 32])]),  # 转换大小
                     download=True,  # 没有则下载
                     train=False)  # 测试数据集
```

查看数据集大小，训练集50000\*3\*32\*32，测试集10000\*3\*32\*32：

> print(train_dataset.data.shape)  # (50000, 32, 32, 3)
> print(test_dataset.data.shape)  # (10000, 32, 32, 3)
>
> print(len(train_dataset.targets))  # 标签，50000

### 2. 构建网络模型

```python
# 构建网络模型
class MyNet(nn.Module):
    def __init__(self):
        super(MyNet, self).__init__()
 
        self.net = nn.Sequential(
            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(5, 5), stride=(1, 1)),    # 卷积层，32*5*5
            nn.ReLU(),    # ReLU激活
            nn.MaxPool2d(kernel_size=2, stride=2),    # 最大池化
            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(5, 5), stride=(1, 1)),    # 卷积层，64*5*5
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Flatten(),    # Flatten层
            nn.Dropout(p=0.5),    # dropout不训练部分节点
            nn.Linear(in_features=64 * 5 * 5, out_features=1600),    # 全连接
            nn.Dropout(p=0.5),
            nn.Linear(in_features=1600, out_features=10),    # 输出层
        )
 
    def forward(self, x):    # 前向传播
        return self.net(x)
```

网络模型需要根据训练效果进行调整优化。

### 3. 训练参数

使用DataLoader()分批batch获取数据并传入网络进行训练；设置训练迭代次数epochs；设置GPU训练，需要在每一个input输入和输出target后加上 `.to(device)`。

设置优化器、学习率和交叉熵损失

```python
epochs = 50  # 训练轮数
display = 1000  # 显示步长
train_batch_size = 128  # 训练批次大小
 
# 数据加载器（迭代器，每次迭代返回一个batch大小的数据data+标签target）
train_dataloader = DataLoader(dataset=train_dataset, batch_size=train_batch_size, shuffle=True)
 
moduel = MyNet()  # 实例化模型
device = torch.device('cuda:1')
moduel.to(device)
 
optimizer = optim.Adam(params=moduel.parameters(), lr=1e-3)  # 优化器
criteon = torch.nn.CrossEntropyLoss()  # 交叉熵损失
```

### 4. 进行训练

```python
moduel.train()  # 当前为训练模式
for epoch in range(epochs):
    for i, train_data in enumerate(train_dataloader):
        data, target = train_data  # 获取数据和标签
        data = data.to(device)
        target = target.to(device)
        pred = moduel(data)  # 模型输出预测值
        loss = criteon(pred, target)  # 损失
 
        optimizer.zero_grad()  # 固定搭配这三句。梯度清零
        loss.backward()        # 反向传播
        optimizer.step()    # 更新梯度
 
        if i % display == 0:
            print('Epoch', epoch + 1, (i + 1) * 32, '/ 50000', 'Loss', loss.item(), )
 
# 保存训练模型
torch.save(obj=moduel.state_dict(), f='models/cifar10.pth')
```

> Epoch 1 32 / 50000 Loss 2.306429862976074
> Epoch 2 32 / 50000 Loss 1.3437093496322632
> Epoch 3 32 / 50000 Loss 1.311663031578064
> Epoch 4 32 / 50000 Loss 1.275579810142517
> Epoch 5 32 / 50000 Loss 1.1473222970962524
> Epoch 6 32 / 50000 Loss 1.0987987518310547
> Epoch 7 32 / 50000 Loss 1.0071738958358765
> Epoch 8 32 / 50000 Loss 1.0531636476516724
> Epoch 9 32 / 50000 Loss 0.9103541374206543
> Epoch 10 32 / 50000 Loss 0.9287123084068298
>
> ......

### 5. 进行验证

```python
# 数据批加载器
test_batch_size = 64  # 测试批次大小
test_dataloader = DataLoader(dataset=train_dataset, batch_size=test_batch_size, shuffle=True)
 
# 加载训练模型
model = MyNet().to(device)
model.load_state_dict(torch.load('models/cifar10.pth'))
moduel.eval()        # 当前为验证模式
acc = 0        # 精度
total = 0    # 验证数
with torch.no_grad():        # 验证模式下不用求导
    for data, target in test_dataloader:
        data = data.to(device)
        target = target.to(device)    # shape = [batch]
        # 预测结果取argmax
        pred = moduel(data)        # shape = [batch, 10]
        pred = pred.argmax(dim=1)    # 取第二个维度的argmax，shape=[batch]
        # 比较pred和target，结果为True/Fasle，转为浮点数1/0，计数得到正确数
        acc += torch.eq(pred, target).float().sum().item()
        total += data.size(0)
 
    acc = acc / total
    print('Validate accuracy: {}'.format(acc))
```

> Validate accuracy: 0.79068

最终达到79%的准确率，Not too bad.

【参考】

https://www.bilibili.com/video/BV1Sr4y1N71H?p=69

https://blog.csdn.net/XLcaoyi/article/details/109754507
